{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prTG6xHHvZ9_",
    "outputId": "15052d4c-910c-4fb5-aff9-197f26b6a9a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at d:\\anaconda3\\envs\\huggingman\\lib\\site-packages\\huggingface_hub-0.23.3-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in d:\\anaconda3\\envs\\huggingman\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at d:\\anaconda3\\envs\\huggingman\\lib\\site-packages\\huggingface_hub-0.23.3-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary libraries\n",
    "!pip install pandas\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ByG5wBPdv4O2"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8XCIGCP4wV1l"
   },
   "outputs": [],
   "source": [
    "# Read the xlsx files\n",
    "text_summary_data = pd.read_excel('text_summary_datasets_v2.xlsx')\n",
    "training_data = pd.read_excel('training_data_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "wLtNfTxHwqT_",
    "outputId": "c4534c00-c162-4c6f-f304-202b4e775c53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Category</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_759</th>\n",
       "      <th>dim_760</th>\n",
       "      <th>dim_761</th>\n",
       "      <th>dim_762</th>\n",
       "      <th>dim_763</th>\n",
       "      <th>dim_764</th>\n",
       "      <th>dim_765</th>\n",
       "      <th>dim_766</th>\n",
       "      <th>dim_767</th>\n",
       "      <th>dim_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.882278</td>\n",
       "      <td>-0.647234</td>\n",
       "      <td>0.050173</td>\n",
       "      <td>-0.448188</td>\n",
       "      <td>-0.175582</td>\n",
       "      <td>0.125284</td>\n",
       "      <td>-0.335781</td>\n",
       "      <td>-0.396106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568470</td>\n",
       "      <td>-0.326577</td>\n",
       "      <td>0.026089</td>\n",
       "      <td>-0.407658</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.121949</td>\n",
       "      <td>-0.386429</td>\n",
       "      <td>0.135763</td>\n",
       "      <td>0.516049</td>\n",
       "      <td>0.731324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.702665</td>\n",
       "      <td>-0.462591</td>\n",
       "      <td>0.162085</td>\n",
       "      <td>-0.029182</td>\n",
       "      <td>-0.280842</td>\n",
       "      <td>0.047459</td>\n",
       "      <td>0.109864</td>\n",
       "      <td>-0.540210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249440</td>\n",
       "      <td>-0.422917</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>-0.226271</td>\n",
       "      <td>-0.324386</td>\n",
       "      <td>-0.036914</td>\n",
       "      <td>-0.588373</td>\n",
       "      <td>-0.344278</td>\n",
       "      <td>0.329853</td>\n",
       "      <td>0.195897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.327257</td>\n",
       "      <td>-0.397209</td>\n",
       "      <td>0.035037</td>\n",
       "      <td>-0.064671</td>\n",
       "      <td>-0.435734</td>\n",
       "      <td>0.535525</td>\n",
       "      <td>0.134867</td>\n",
       "      <td>-0.213102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>-0.191510</td>\n",
       "      <td>-0.068998</td>\n",
       "      <td>-0.262279</td>\n",
       "      <td>-0.214397</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>-0.503536</td>\n",
       "      <td>0.142249</td>\n",
       "      <td>0.206015</td>\n",
       "      <td>0.182094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.793734</td>\n",
       "      <td>-0.470964</td>\n",
       "      <td>-0.278644</td>\n",
       "      <td>-0.292047</td>\n",
       "      <td>-0.565868</td>\n",
       "      <td>0.546791</td>\n",
       "      <td>0.604674</td>\n",
       "      <td>-0.069190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387789</td>\n",
       "      <td>-0.596448</td>\n",
       "      <td>-0.291108</td>\n",
       "      <td>-0.320205</td>\n",
       "      <td>-0.362207</td>\n",
       "      <td>0.179917</td>\n",
       "      <td>-0.600026</td>\n",
       "      <td>-0.200465</td>\n",
       "      <td>0.776508</td>\n",
       "      <td>-0.155819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.272840</td>\n",
       "      <td>-0.556684</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>-0.229906</td>\n",
       "      <td>-0.495732</td>\n",
       "      <td>0.176596</td>\n",
       "      <td>-0.141926</td>\n",
       "      <td>-0.352247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660122</td>\n",
       "      <td>-0.534026</td>\n",
       "      <td>0.347033</td>\n",
       "      <td>-0.279629</td>\n",
       "      <td>-0.397189</td>\n",
       "      <td>0.226515</td>\n",
       "      <td>-0.547098</td>\n",
       "      <td>0.431136</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>0.422797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  Category     dim_1     dim_2     dim_3     dim_4     dim_5  \\\n",
       "0      0         0 -0.882278 -0.647234  0.050173 -0.448188 -0.175582   \n",
       "1      1         0 -0.702665 -0.462591  0.162085 -0.029182 -0.280842   \n",
       "2      2         0 -0.327257 -0.397209  0.035037 -0.064671 -0.435734   \n",
       "3      3         0 -0.793734 -0.470964 -0.278644 -0.292047 -0.565868   \n",
       "4      4         0 -0.272840 -0.556684  0.001737 -0.229906 -0.495732   \n",
       "\n",
       "      dim_6     dim_7     dim_8  ...   dim_759   dim_760   dim_761   dim_762  \\\n",
       "0  0.125284 -0.335781 -0.396106  ...  0.568470 -0.326577  0.026089 -0.407658   \n",
       "1  0.047459  0.109864 -0.540210  ...  0.249440 -0.422917  0.033820 -0.226271   \n",
       "2  0.535525  0.134867 -0.213102  ...  0.710835 -0.191510 -0.068998 -0.262279   \n",
       "3  0.546791  0.604674 -0.069190  ...  0.387789 -0.596448 -0.291108 -0.320205   \n",
       "4  0.176596 -0.141926 -0.352247  ...  0.660122 -0.534026  0.347033 -0.279629   \n",
       "\n",
       "    dim_763   dim_764   dim_765   dim_766   dim_767   dim_768  \n",
       "0 -0.162295 -0.121949 -0.386429  0.135763  0.516049  0.731324  \n",
       "1 -0.324386 -0.036914 -0.588373 -0.344278  0.329853  0.195897  \n",
       "2 -0.214397  0.095195 -0.503536  0.142249  0.206015  0.182094  \n",
       "3 -0.362207  0.179917 -0.600026 -0.200465  0.776508 -0.155819  \n",
       "4 -0.397189  0.226515 -0.547098  0.431136  0.102714  0.422797  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first few rows of the training data\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2dc0d30y0gkn"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into features (X) and target (y)\n",
    "x = training_data.drop(columns=[\"Index\",\"Category\"])\n",
    "y = training_data[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a3b16AOO1IX3"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDv_zC-31UMR",
    "outputId": "fcac43ad-d8b4-4421-9575-afd398b9090b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      "[[11  0  0  0]\n",
      " [ 1 17  2  0]\n",
      " [ 0  1 14  0]\n",
      " [ 0  2  0 12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       0.85      0.85      0.85        20\n",
      "           2       0.88      0.93      0.90        15\n",
      "           3       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.91      0.91      0.91        60\n",
      "weighted avg       0.90      0.90      0.90        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Classifier\n",
    "# Initializing the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "rf_class_report = classification_report(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest Classifier\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(rf_conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(rf_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXQs8smW1c-V",
    "outputId": "119b9343-ac6b-4504-e1df-c4ee538f05bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine Classifier\n",
      "Accuracy: 0.9833333333333333\n",
      "Confusion Matrix:\n",
      "[[11  0  0  0]\n",
      " [ 1 19  0  0]\n",
      " [ 0  0 15  0]\n",
      " [ 0  0  0 14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.95      0.97        20\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.98      0.99      0.98        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Support Vector Machine Classifier\n",
    "# Initializing the SVM classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Training the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "svm_y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "svm_conf_matrix = confusion_matrix(y_test, svm_y_pred)\n",
    "svm_class_report = classification_report(y_test, svm_y_pred)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Classifier\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(svm_conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(svm_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\huggingman\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\anaconda3\\envs\\huggingman\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# import required libs\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\huggingman\\Lib\\site-packages\\huggingface_hub-0.23.3-py3.8.egg\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer and bert\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltk libs\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text pre-processing function\n",
    "def preprocess_text(text):\n",
    "    # case standardization\n",
    "    text = text.lower() # dont care about capitalization yet\n",
    "    \n",
    "    # puntuation removal\n",
    "    text = text.replace('\"', '') # our text consists of multiple sentences, some punctuations are needed\n",
    "\n",
    "    # tokenized text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # stop word removal\n",
    "    # new_tokens = []\n",
    "    # for token in tokens:\n",
    "    #    if token.lower() not in stop_words:\n",
    "    #        new_tokens.append(token)\n",
    "    '''\n",
    "    original:\n",
    "    ['the', 'diagnosis', 'of', 'v', '##kh', 'followed', 'revised', 'diagnostic', 'criteria', 'by', 'the', 'internation', ...]\n",
    "    remove stop words:\n",
    "    ['diagnosis', 'v', '##kh', 'followed', 'revised', 'diagnostic', 'criteria', 'international', ...]\n",
    "    Thus don't remove stop words, it might lead to poor BERT semantic understand. \n",
    "    '''\n",
    "\n",
    "    # lemmatizer and stemmer\n",
    "    # Lemmatization and Stemming\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # print(tokens)\n",
    "    # print(lemmatized_tokens)\n",
    "    # print(stemmed_tokens)\n",
    "    '''\n",
    "    lemmatized:\n",
    "    ['the', 'diagnosis', 'of', 'v', '##kh', 'followed', 'revised', 'diagnostic', 'criterion', 'by', 'the', 'international', ...]\n",
    "    stemmed:\n",
    "    ['the', 'diagnosi', 'of', 'v', '##kh', 'follow', 'revis', 'diagnost', 'criteria', 'by', 'the', 'intern', ...]\n",
    "    Stemmed is bad here, choose lemmatizer over stemmer.\n",
    "    '''\n",
    "\n",
    "    # change tokens back to senteces\n",
    "    def detokenize(tokens):\n",
    "        new_tokens = []\n",
    "        for token in tokens:\n",
    "            if token.startswith(\"##\"):\n",
    "                new_tokens[-1] += token[2:]\n",
    "            else:\n",
    "                new_tokens.append(token)\n",
    "        text = \" \".join(new_tokens)\n",
    "        text = re.sub(r'\\s([?.!,\\'-](?:\\s|$))', r'\\1', text)\n",
    "        return text\n",
    "\n",
    "    text = detokenize(lemmatized_tokens)\n",
    "\n",
    "    # capitalize first alphabet of each sentence\n",
    "    text = re.sub(r\"(^|[.!?]\\s+)(\\w+)\", lambda match: match.group(1) + match.group(2).capitalize(), text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "'''\n",
    "choose BERT to get text semantic meaning to be used for classification and clustering. This is more advanced than keywords counting.\n",
    "'''\n",
    "def toBert(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "    outputs = bert_model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "    return outputs.last_hidden_state[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Real Case Dataset [0, 1, 2, 3]: [Healthcare, AI, IoT, BlockChain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_paragraph_0 = \"Seven out of 12 patients no longer needed daily insulin shots after receiving a full dose of the gene therapy, dubbed VX-800, researchers reported Friday at the American Diabetes Association annual meeting in Orlando, FL. Another two needed about 70% less insulin daily to keep their blood sugar stable, results show. This positive data adds to the growing body of evidence for VX-880 potential to revolutionize the treatment of type 1 diabetes, said researcher Dr. Piotr Witkowski, director of the pancreatic and islet transplant program at the University of Chicago. People with type 1 diabetes arent able to produce enough insulin to keep blood sugar levels stable. Type 1 diabetes occurs when the immune system mistakenly targets and attacks the islet cells in the pancreas that generate insulin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_paragraph_1 = \"The film is brief and its AI origins are only really obvious when it is paused. Otherwise, you might think it was simply the victim of an overly enthusiastic editor with access to some powerful visual effects software and actors who don't know how to perform in front of a green screen. Overall, it manages to mostly avoid the uncanny valley except for when the young founder smiles, then it a little too much like watching The Polar Express. Still, when considering it was produced with the alpha version of Sora and with relatively limited time and resources, you can see why some are very excited about Sora. Through Sora, we were able to tell this incredible story with remarkable speed and efficiency, Native Foreign Chief Creative Officer and the film's director Nik Kleverov said in a statement.  Toys R Us is the perfect brand to embrace this AI-forward strategy, and we are thrilled to collaborate with their creative team to help lead the next wave of innovative storytelling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_paragraph_2 = \"Programmable networking protocols, such as OpenFlow, direct traffic among network devices in an SDN network. The Open Networking Foundation (ONF) helped to standardize the OpenFlow protocol and other open source SDN technologies. By combining these components, organizations get a simpler, centralized way to manage networks. SDN strips away the routing and packet forwarding functions, known as the control plane, from the data plane or underlying infrastructure. SDN then implements controllers, considered the brain of the SDN network, and layers them above the network hardware in the cloud or on-premises. This lets teams use policy-based management—a kind of automation—to manage network control directly. SDN controllers tell switches where to send packets. In some cases, virtual switches embedded in software or hardware replace the physical switches. This consolidates their functions into a single, intelligent switch that can check data packets and their virtual machine destinations to ensure there are no issues before moving packets along.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_paragraph_3 = \"ou might be familiar with spreadsheets or databases. A blockchain is somewhat similar because it is a database where information is entered and stored. But the key difference between a traditional database or spreadsheet and a blockchain is how the data is structured and accessed. A blockchain consists of programs called scripts that conduct the tasks you usually would in a database: Entering and accessing information and saving and storing it somewhere. A blockchain is distributed, which means multiple copies are saved on many machines, and they must all match for it to be valid.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess_text(new_paragraph_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = toBert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.expand_dims(outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'dim_{i}' for i in range(1, 769)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(outputs, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "svm_y_pred = svm_clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_y_pred # 0 means Healthcare is predicted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess_text(new_paragraph_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = toBert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.expand_dims(outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'dim_{i}' for i in range(1, 769)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(outputs, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "svm_y_pred = svm_clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_y_pred # 1 means AI is predicted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess_text(new_paragraph_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = toBert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.expand_dims(outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'dim_{i}' for i in range(1, 769)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(outputs, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "svm_y_pred = svm_clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_y_pred # 2 means IoT is predicted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlockChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess_text(new_paragraph_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = toBert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.expand_dims(outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'dim_{i}' for i in range(1, 769)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(outputs, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "svm_y_pred = svm_clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_y_pred # 3 means BlockChain is predicted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
